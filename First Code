import Speech
import UIKit

class SpeechRecognitionManager: NSObject, SFSpeechRecognizerDelegate {
    
    private let speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "en-US"))
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private let audioEngine = AVAudioEngine()
    
    weak var delegate: SearchTextFieldDelegate?

    func requestSpeechPermission() {
        SFSpeechRecognizer.requestAuthorization { authStatus in
            switch authStatus {
            case .authorized:
                print("Speech recognition authorized")
            case .denied:
                print("Speech recognition denied")
            case .restricted:
                print("Speech recognition restricted")
            case .notDetermined:
                print("Speech recognition not determined")
            @unknown default:
                break
            }
        }
    }

    func startListening() {
        requestSpeechPermission()

        let inputNode = audioEngine.inputNode
        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        
        guard let recognitionRequest = recognitionRequest else {
            fatalError("Unable to create a recognition request")
        }
        
        recognitionRequest.shouldReportPartialResults = true

        recognitionTask = speechRecognizer?.recognitionTask(with: recognitionRequest, resultHandler: { result, error in
            if let result = result {
                let spokenText = result.bestTranscription.formattedString
                self.delegate?.micIconTapped(recognizedText: spokenText)
            } else if let error = error {
                print("Speech recognition error: \(error)")
            }
        })
        
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { buffer, _ in
            self.recognitionRequest?.append(buffer)
        }
        
        audioEngine.prepare()
        try? audioEngine.start()

        print("Listening for speech...")
    }

    func stopListening() {
        audioEngine.stop()
        recognitionRequest?.endAudio()
        recognitionTask?.cancel()
    }
}


import UIKit

@objc public protocol SearchTextFieldDelegate: AnyObject {
    func searchIconTapped(searchText: String)
    func micIconTapped(recognizedText: String)
}

class SearchViewController: UIViewController, SearchTextFieldDelegate {

    var textField: UITextField!
    var searchIcon: UIImageView!
    var micIcon: UIImageView!
    weak var delegate: SearchTextFieldDelegate?

    override func viewDidLoad() {
        super.viewDidLoad()
        setupView()
    }

    open override func setupView() {
        super.viewDidLoad()
        
        let searchTapGestureRecognizer = UITapGestureRecognizer(target: self, action: #selector(self.searchIconTapped))
        searchIcon.addGestureRecognizer(searchTapGestureRecognizer)

        let micTapGestureRecognizer = UITapGestureRecognizer(target: self, action: #selector(self.micIconTapped))
        micIcon.addGestureRecognizer(micTapGestureRecognizer)
    }

    @objc func searchIconTapped(tapGestureRecognizer: UITapGestureRecognizer) {
        delegate?.searchIconTapped(searchText: textField.text ?? "")
    }

    @objc func micIconTapped(tapGestureRecognizer: UITapGestureRecognizer) {
        let speechRecognizerVC = SpeechRecognitionManager()
        speechRecognizerVC.delegate = self
        speechRecognizerVC.startListening()
    }

    func micIconTapped(recognizedText: String) {
        textField.text = recognizedText
        delegate?.searchIconTapped(searchText: recognizedText)
    }

    func searchIconTapped(searchText: String) {
        // Add any extra logic if needed
    }
}
